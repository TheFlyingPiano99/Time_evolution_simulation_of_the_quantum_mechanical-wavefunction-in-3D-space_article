\section{Used method}
\label{sec:used_method}

In our simulation we numerically solve the time dependent Schrödinger equation.
There are multiple available algorithms for this task.
A widely used category of solving strategies are the \acrfull{fdtd} methods.
This approach is also widely adopted to simulate the solution of Maxwell equations \cite{maxwell1865, Ulf2001}.
\acrfull{fdtdq} however exhibit numerical instability \cite{Soriano2004}.
After a longer sequence of simulation steps the solutions diverge from the ground truth.
There are various alterations of the base method.
One such method was proposed by Min Zhu et al. \cite{Zhu2014} in the year 2014.
Their algorithm is called the \acrfull{rkhofdtd}.
In 2021, a follow up paper \cite{Zhu_Wang_2021} demonstrated the superiority of \acrshort{rkhofdtd} over the basic \acrshort{fdtdq} approach.
In the same year Frederick Ira Moxley et al. \cite{MOXLEY20122434} proposed another method based on \acrshort{fdtdq}.
These methods solve the majority of problems related to \acrshort{fdtdq}.

However in our work we use a different approach.
Back in 1982, D Kosloff and R Kosloff proposed a method \cite{KOSLOFF198335} to solve the time-dependent Schrödinger equation efficiently using Fourier transformation.
The advantage of this algorithm is the high numerical stability of the time evolution step.
In the adopted \acrshort{fft} method no signs of divergence are present even after a large number of simulation steps.
The time development step of the algorithm has a time complexity of $\mathcal{O}(N\log N)$ since it only uses six \acrshort{fft} runs ($\mathcal{O}(N\log N)$ each) and three element wise multiplication between tensors ($\mathcal{O}(N)$ each).
The amount of \acrshort{fft} runs and multiplications can be reduced further if we don't want to read the results of the time development in each step.
A significant speed up can be reached by using parallelized implementation of the \acrshort{fft} algorithm as we did by using an efficient \acrshort{gpu} implementation.
In the following part we would like to explain the \acrshort{fft} method in detail.

The idea of the method is to discretize the space of the simulation and to construct anohter discretized space in which Hermitian operators of the original space are mapped into Hermitian operators. 











\begin{equation}
	\label{eq:schrodinger_formal_solution}
	\psi(\vec{r}; t) = U\psi(\vec{r}, t_0)\;\;\;\;\;\;\;\; U = e^{-iH(t-t_0)}
\end{equation}
Here $U$ is the time development operator.
The exponent containing $H$ can not be trivially factored.
We can use an approximation described in equation~\ref{eq:solution_approximation}.
\begin{equation}
	\label{eq:solution_approximation}
	e^{-i(K + V)\delta{}t} \approx e^{-iK\delta{}t/2}e^{-iV\delta{}t}e^{-iK\delta{}t/2}
\end{equation}
The error of this approximation is $O\left[(\delta{}t)^3 \right]$.
We have to consider this when designing the time resolution of the simulation.
The evolution operator is now split into three consecutive steps.
These are a free propagation for time $\delta{}t / 2$, a potential only propagation for $\delta{}t$ and another free propagation for $\delta{}t / 2$.
Since the effect of $V$ is a multiplication with $V(\vec{r})$ we can write the potential propagator as a multiplication with $e^{-iV(\vec{r})\delta{}t}$.
The effect of the free propagator is simple when applied in the $k$ momentum space.
In this case it is simply a multiplication with $e^{i|k|^2\delta{}t/4}$.
To use this formula we have to convert from real space to momentum space and backward.
To do this we must calculate the Fourier transform of the wave function.
On the computer this is approximated by calculating the Discrete Fourier Transform (DFT).
DFT can be implemented with an algorithmic complexity of $O\left[n\,log(n)\right]$  with the Fast Fourier Transform (FFT) algorithm.
This method utilises the symmetries naturally occurring while calculating the DFT by definition.
Namely that you can reuse some values by pairing the odd and even indexed members of the input vector.

Given a $\psi_n$ current state, the next state occurring after $\delta{}t$ time can be obtained by executing the following steps.
\begin{enumerate}
	\item{$\psi_n^{(1)} := FFT^{-1}\left[ P_{kinetic}(\delta{}t/2)\;FFT(\psi_n) \right]$}
	\item{$\psi_n^{(2)} := P_{potential}(\delta{}t)\;\psi_n^{(1)}$}
	\item{$\psi_{n+1} := FFT^{-1}\left[ P_{kinetic}(\delta{}t/2)\;FFT(\psi_n^{(2)}) \right]$}
\end{enumerate}
Here $P_{kinetic}(\delta{}t/2)$ is the previously discussed free propagator applied by multiplying with $e^{i|k|^2\delta{}t/4}$, and $P_{potential}(\delta{}t)$ is the potential propagator applied by multiplying with $e^{-iV(\vec{r})\delta{}t}$.

To obtain a convergent and aliasing free simulation one must choose small enough $\delta{}x,\; \delta{}y$ grid resolution that is smaller than the \textit{de Broglie} wavelength of the simulated system.

The output of the simulation is the probability density function of the simulated volume.
This can be obtained by calculating the square of the absolute value of the wave function for each position as seen in equation~\ref{eq:probability_density}.
\begin{equation}
	\label{eq:probability_density}
	p(\vec{r}; t) = |\psi(\vec{r}, t)|^2
\end{equation}


